dataset <- read.csv("C:/Users/isabe/OneDrive - Università degli Studi di Milano/3rd trimester/statistical learning/group project/QDV2021-main/QDV2021-main/20211213_QDV2021_001.csv")
View(dataset)
unique(dateset$indicatore)
unique(dataset$indicatore)
unique(dateset$INDICATORE)
unique(dataset$INDICATORE)
qualita_vita_2021 <- read.csv("C:/Users/isabe/OneDrive - Università degli Studi di Milano/3rd trimester/statistical learning/group project/QDV2021-main/QDV2021-main/qualita_vita_2021.csv")
View(qualita_vita_2021)
n <- nrow(qualita_vita_2021)
p <- ncol(qualita_vita_2021)
n
p
qualita_vita_2021<-qualita_vita_2021[,-1]
n <- nrow(qualita_vita_2021)
p <- ncol(qualita_vita_2021)
n
p
qualita_vita_2021 <- read.csv("C:/Users/isabe/OneDrive - Università degli Studi di Milano/3rd trimester/statistical learning/group project/QDV2021-main/QDV2021-main/qualita_vita_2021.csv")
View(qualita_vita_2021)
dataset <- read.csv("C:/Users/isabe/OneDrive - Università degli Studi di Milano/3rd trimester/statistical learning/group project/QDV2021-main/QDV2021-main/qualita_vita_2021.csv")
data <- dataset[,-1]
n <- nrow(data)
p <- ncol(data)
n
p
#DESCRIPTIVE
#mean and std
medie <- colMeans(data)
scarto <- apply(data, 2, sd)
medie
length(medie)
scarto
#PCA from covariance matrix
sigma <- cov(data)
eigen(sigma)
autoval <- eigen(sigma)$values
autovec <- eigen(sigma)$vectors
autovec
autovec
autoval
#PCA from correlation matrix
rho <- cor(data)
eigen(rho)
autoval <- eigen(rho)$values
autovec <- eigen(rho)$vectors
autovec
comp<-round(cbind(-eigen(rho)$vectors[,1]*sqrt(autoval[1]),-eigen(rho)$vectors[,2]*sqrt(autoval[2])),3)
colnames(comp)<-c("Comp1","Comp2")
comp
pvarsp = autoval/p
pvarspcum = cumsum(pvarsp)
pvarsp
M <- colMeans(data)
M <- colMeans(data)
sigma <- apply(data, 2, sd)
descriptive<-round(cbind(M, sigma),2)
descriptive
rho <- cor(data)
round(rho,3)
round(rho,3)
eigen(rho)
autoval <- eigen(rho)$values
autovec <- eigen(rho)$vectors
pvarsp = autoval/p
pvarspcum = cumsum(pvarsp)
tab<-round(cbind(autoval,pvarsp*100,pvarspcum*100),3)
colnames(tab)<-c("eigenvelues", "% variance","% cum variance")
tab
plot(autoval, type="b", main="Scree Diagram", xlab="Number of Component", ylab="Eigenvalues")
abline(h=1, lwd=3, col="red")
acp<-princomp(data, cor=T)
summary(princomp(data, cor=T))
screeplot(princomp(data, cor=T))
plot(princomp(data, cor=T)$scores)
text(princomp(data, cor=T)$scores, rownames(data))
abline(h=0, v=0)
row.names(data)
row.names(dataset)
row.names(data)<-dataset$DENOMINAZIONE.CORRENTE
row.names(data)
plot(princomp(data, cor=T)$scores)
text(princomp(data, cor=T)$scores, rownames(data))
abline(h=0, v=0)
dataset <- read.csv("C:/Users/isabe/OneDrive - Università degli Studi di Milano/3rd trimester/statistical learning/group project/QDV2021-main/QDV2021-main/qualita_vita_2021.csv")
library(haven)
library(car)
#### Analysis for italian province ####
rownames(dataset)<-dataset$DENOMINAZIONE.CORRENTE
dataset<-dataset[,-1]
head(dataset)
summary(dataset)
summary(scale(dataset)
## function for agglomeration program
agglo <- function(hc){
data.frame(row.names=paste0("Cluster",seq_along(hc$height)),
height=hc$height,
components=ifelse(hc$merge<0,
hc$labels[abs(hc$merge)], paste0("Cluster",hc$merge)),
stringsAsFactors=FALSE) }
## function for agglomeration program
agglo <- function(hc){
data.frame(row.names=paste0("Cluster",seq_along(hc$height)),
height=hc$height,
components=ifelse(hc$merge<0, hc$labels[abs(hc$merge)], paste0("Cluster",hc$merge)),
stringsAsFactors=FALSE) }
opar <- par(mfrow = c(1, 3))
### average linkage
h1<-hclust(ds, method="average")
ds<-dist(scale(dataset))
### average linkage
h1<-hclust(ds, method="average")
agglo(h1)
plot(h1, main="average linkage")
### complete linkage
h2<-hclust(ds, method="complete")
agglo(h2)
install.packages("dendextend")
install.packages("circlize")
# create a dendrogram
hc <- hclust(dist(datasets::dataset))
dend <- as.dendrogram(hc)
# create a dendrogram
hc <- hclust(dist(datasets::dataset))
# create a dendrogram
hc <- hclust(dist(dataset))
dend <- as.dendrogram(hc)
# modify the dendrogram to have some colors in the branches and labels
dend <- dend %>%
color_branches(k=4) %>%
color_labels
library(diplyr)
library(dplyr)
# modify the dendrogram to have some colors in the branches and labels
dend <- dend %>%
color_branches(k=4) %>%
color_labels
# plot the radial plot
par(mar = rep(0,4))
# circlize_dendrogram(dend, dend_track_height = 0.8)
circlize_dendrogram(dend, labels_track_height = NA, dend_track_height = .3)
library(circlize)
# circlize_dendrogram(dend, dend_track_height = 0.8)
circlize_dendrogram(dend, labels_track_height = NA, dend_track_height = .3)
### complete linkage
h2<-hclust(ds, method="complete")
agglo(h2)
plot(h2, main="complete linkage")
### legame ward
h3<-hclust(ds, method="ward.D2")
agglo(h3)
plot(h3, main="Ward linkage")
average <- cutree(h1, k=5)
complete<- cutree(h2, k=5)
ward<- cutree(h3, k=5)
table(average,complete)
table(average,ward)
table(complete,ward)
### dendrograms
plot(h1, main="Complete linkage")
rect.hclust(h2, 5)
h2cluster <- cutree(h2, k=5)
h2cluster
plot(dataset, col=h2cluster, main="complete likage")
table(h2cluster)
## explore solution
medie<-aggregate(oecd, list(h2cluster), mean)
medie
## explore solution
medie<-aggregate(dataset, list(h2cluster), mean)
medie
## standardized variable
mediez<-aggregate(scale(dataset), list(h2cluster), mean)
mediez
##### calculate R^2
mydata<-dataset
mydata$group<-h2cluster
R2 <- rep(NA, (ncol(mydata)-1))
for(i in 1:(ncol(mydata)-1))
R2[i] <- anova(aov(mydata[,i] ~ mydata[,ncol(mydata)]))[1,2]/(anova(aov(mydata[,i] ~ mydata[,ncol(mydata)]))[1,2]+anova(aov(mydata[,i] ~ mydata[,ncol(mydata)]))[2,2])
R2
mydata<-mydata[,-ncol(mydata)]
col<-colnames(mydata)
finali<-cbind(col,R2)
finali
##### K means
# How many clusters??
wss <- (nrow(mydata))*sum(apply(mydata,2,var))
for (i in 2:10) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:10, wss, type="b", xlab="Numero of cluster", ylab="Within Deviance")
# Explore K mean solution
fit <- kmeans(mydata, 4) # 4 cluster solution
aggregate(mydata,by=list(fit$cluster),FUN=mean)
# add cluster to data
mydata <- data.frame(mydata, fit$cluster)
table(h2cluster,fit$cluster)
n <- nrow(dataset)
p <- ncol(dataset)
# descriptives:
medie <- colMeans(dataset)
scarto <- apply(dataset, 2, sd)
descrittive<-round(cbind(medie, scarto),2)
descrittive
## PCA from correlation:
rho <- cor(dataset)
eigen(rho)
## PCA from correlation:
rho <- cor(dataset)
eigen(rho)
autoval <- eigen(rho)$values
autovec <- eigen(rho)$vectors
# Select components
pvarsp = autoval/p
pvarspcum = cumsum(pvarsp)
pvarsp
# Scree Diagram:
plot(autoval, type="b", main="Scree Diagram", xlab="Components", ylab="Eigenvalue")
### Interpret the components:
eigen(rho)$vectors[,1:6]
### Interpret the components:
eigen(rho)$vectors[,1:2]
#  Component matrix, obtained by multiplying the eigenvector by the root of the respective eigenvalue (we change the sign only for interpretative reasons)
comp<-round(cbind(-eigen(rho)$vectors[,1]*sqrt(autoval[1]),-eigen(rho)$vectors[,2]*sqrt(autoval[2])),3)
rownames(comp)<-row.names(descrittive)
colnames(comp)<-c("Comp1","Comp2")
comp
# the sum of the squares of the values of each row of the component matrix is the respective commonality
comunality<-comp[,1]^2+comp[,2]^2
comp<-cbind(comp,comunality)
comp
# scores:
dataset.scale <- scale(dataset, T, T)
punteggi <- dataset.scale%*%autovec[,1:2]
# standardized scores
punteggiz<-round(cbind(-punteggi[,1]/sqrt(autoval[1]),-punteggi[,2]/sqrt(autoval[2])),2)
plot(punteggiz, main="Score plot",
xlab="comp1",ylab="comp2")
text(punteggiz, rownames(oecd))
text(punteggiz, rownames(dataset))
abline(v=0,h=0,col="red")
# loadinngs
plot(comp[,1:2], main="Loadings plot",
xlab="comp1",ylab="comp2", xlim=range(-1,1))
text(comp, rownames(comp))
abline(v=0,h=0,col="red")
opar <- par(mfrow = c(1, 1))
par(mfrow = c(1, 1))
# loadinngs
plot(comp[,1:2], main="Loadings plot",
xlab="comp1",ylab="comp2", xlim=range(-1,1))
text(comp, rownames(comp))
abline(v=0,h=0,col="red")
#### princomp :
acp<-princomp(dataset, cor=T)
summary(princomp(dataset, cor=T))
# number of components:
screeplot(princomp(dataset, cor=T))
# plots:
plot(princomp(dataset, cor=T)$scores)
text(princomp(dataset, cor=T)$scores, rownames(oecd))
text(princomp(dataset, cor=T)$scores, rownames(dataset))
abline(h=0, v=0)
## biplot
biplot(acp)
dataset <- read.csv("C:/Users/isabe/OneDrive - Università degli Studi di Milano/3rd trimester/statistical learning/group project/QDV2021-main/QDV2021-main/qualita_vita_2021.csv")
str(dataset)
dataset <- read.csv("C:/Users/isabe/OneDrive - Università degli Studi di Milano/3rd trimester/statistical learning/group project/QDV2021-main/QDV2021-main/qualita_vita_2021.csv")
str(dataset)
data <- dataset[,-1]
sigma = cov(data[,2:p])
n <- nrow(data)
p <- ncol(data)
sigma = cov(data[,2:p])
eigen(sigma)
autoval_cov = eigen(sigma)$values
autovec_cov = eigen(sigma)$vectors
rho = cor(data[,2:p])
eigen(rho)
data
str(data)
rho
View(rho)
data <- dataset
n <- nrow(data)
p <- ncol(data)
p
p <- p-1
p
sigma = cov(data[,2:p])
sigma = cov(data[,2:p])
dataset <- read.csv("C:/Users/isabe/OneDrive - Università degli Studi di Milano/3rd trimester/statistical learning/group project/QDV2021-main/QDV2021-main/qualita_vita_2021.csv")
str(dataset)
data <- dataset
n <- nrow(data)
p <- ncol(data)
p <- p-1
sigma = cov(data[,2:p])
View(sigma)
dataset <- read.csv("C:/Users/isabe/OneDrive - Università degli Studi di Milano/3rd trimester/statistical learning/group project/QDV2021-main/QDV2021-main/qualita_vita_2021.csv")
str(dataset)
data <- dataset
n <- nrow(data)
p <- ncol(data)
sigma = cov(data[,2:p])
eigen(sigma)
autoval_cov = eigen(sigma)$values
autovec_cov = eigen(sigma)$vectors
View(sigma)
rho = cor(data[,2:p])
eigen(rho)
autoval_cor = eigen(rho)$values
autovec_cor = eigen(rho)$vectors
autovec_cor = eigen(rho)$vectors
str(data)
corr = matrix(, nrow = 90, ncol = 90)
for (i in 1:90){
corr[,i] = autovec_cor[,i]*sqrt(autoval_cor[i])
}
rownames(corr) = colnames(data[,2:91])
colnames(corr) = 1:90
sigma = cov(data[,2:p])
eigen(sigma)
autoval_cov = eigen(sigma)$values
autovec_cov = eigen(sigma)$vectors
rho = cor(data[,2:p])
eigen(rho)
autoval_cor = eigen(rho)$values
autovec_cor = eigen(rho)$vectors
str(data)
corr_comp = matrix(, nrow = 90, ncol = 90)
for (i in 1:90){
corr_comp[,i] = autovec_cor[,i]*sqrt(autoval_cor[i])
}
rownames(corr_comp) = colnames(data[,2:91])
colnames(corr_comp) = 1:90
corr_comp
heatmap(corr_comp)
?heatmap
pheatmap(corr_comp, cluster_rows=FALSE, cluster_cols=FALSE)
install.packages("pheatmap")
library(pheatmap)
pheatmap(corr_comp, cluster_rows=FALSE, cluster_cols=FALSE)
#analysis of the eigenvalues
pvarsp = autoval/p
pvarspcum = cumsum(pvarsp)
pvarsp
library(haven)
library(car)
#analysis of the eigenvalues
pvarsp = autoval/p
#analysis of the eigenvalues
pvarsp = autoval_cor/p
pvarspcum = cumsum(pvarsp)
pvarsp
pvarspcum
# Scree Diagram:
plot(autoval_cor, type="b", main="Scree Diagram", xlab="Components", ylab="Eigenvalue")
abline(h=1, lwd=3, col="red")
#analysis of the eigenvalues
pvarsp = autoval_cor/p
pvarspcum = cumsum(pvarsp)
pvarsp
pvarspcum
pheatmap(corr_comp, cluster_rows=TRUE, cluster_cols=FALSE)
pheatmap(corr_comp, cluster_rows=FALSE, cluster_cols=FALSE)
autovec_cov
View(autovec_cov)
